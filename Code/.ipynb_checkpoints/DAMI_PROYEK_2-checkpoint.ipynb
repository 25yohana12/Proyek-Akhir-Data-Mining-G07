{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wWBSJKqBzD-c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38
    },
    "id": "wWBSJKqBzD-c",
    "outputId": "203f2aaf-e675-4cc3-91c4-96d362cddff2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-6b8a5533-99f1-4469-9e69-6f61496faee3\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-6b8a5533-99f1-4469-9e69-6f61496faee3\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BgSHBakX4jun",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "BgSHBakX4jun",
    "outputId": "cbd788fd-9a8a-4d11-cd78-d03f2d44ec65"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-101458a4-08d4-4a11-b41b-cffbe5732791\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-101458a4-08d4-4a11-b41b-cffbe5732791\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving GLC25_PA_metadata_train.csv to GLC25_PA_metadata_train.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hkMlPdUP4TFH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "hkMlPdUP4TFH",
    "outputId": "466f0eca-79d4-4d1e-ef28-a7f2ac0f36d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-463c3a67-632e-4c00-bd68-1c3288e06e94\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-463c3a67-632e-4c00-bd68-1c3288e06e94\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving GLC25-PO-train-soilgrids.csv to GLC25-PO-train-soilgrids.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bjQxGT6cFdY1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "bjQxGT6cFdY1",
    "outputId": "0598e773-1a0c-4722-9852-4bdcd782443a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-9bb681b8-4b44-4556-8f96-5a758de72b1b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-9bb681b8-4b44-4556-8f96-5a758de72b1b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving GLC25-PA-train-soilgrids.csv to GLC25-PA-train-soilgrids.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ln6MjLH9Rhcs",
   "metadata": {
    "id": "ln6MjLH9Rhcs"
   },
   "source": [
    "Data Undestanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Msa7nq11pC9b",
   "metadata": {
    "id": "Msa7nq11pC9b"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (4187170142.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    PA_metadata_train_file = 'C:\\Users\\ASUS\\Downloads\\GLC25_PA_metadata_train.csv'\u001b[0m\n\u001b[1;37m                                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets with the new names\n",
    "PA_metadata_train_file = 'GLC25_PA_metadata_train.csv'\n",
    "P0_metadata_train_file = 'GLC25_P0_metadata_train.csv'\n",
    "PA_soil_train_file = 'GLC25-PA-train-soilgrids.csv'\n",
    "P0_soil_train_file = 'GLC25-PO-train-soilgrids.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cF8gGqy-s1P2",
   "metadata": {
    "id": "cF8gGqy-s1P2"
   },
   "outputs": [],
   "source": [
    "PA_metadata_train = pd.read_csv(C:\\Users\\ASUS\\Downloads\\PA_metadata_train_file)\n",
    "P0_metadata_train = pd.read_csv(C:\\Users\\ASUS\\Downloads\\P0_metadata_train_file)\n",
    "PA_soil_train = pd.read_csv(C:\\Users\\ASUS\\Downloads\\PA_soil_train_file)\n",
    "P0_soil_train = pd.read_csv(C:\\Users\\ASUS\\Downloads\\P0_soil_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3q3a9HqXO0PA",
   "metadata": {
    "id": "3q3a9HqXO0PA"
   },
   "outputs": [],
   "source": [
    "PA_metadata_train_top500 = PA_metadata_train.head(500)\n",
    "P0_metadata_train_top500 = P0_metadata_train.head(500)\n",
    "PA_soil_train_top500 = PA_soil_train.head(500)\n",
    "P0_soil_train_top500 = P0_soil_train.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J7EI6i7cs3mY",
   "metadata": {
    "id": "J7EI6i7cs3mY"
   },
   "outputs": [],
   "source": [
    "PA_metadata_train_top500.to_csv('500_PA_metadata_train.csv', index=False)\n",
    "P0_metadata_train_top500.to_csv('500_P0_metadata_train.csv', index=False)\n",
    "PA_soil_train_top500.to_csv('500_PA_soil_train.csv', index=False)\n",
    "P0_soil_train_top500.to_csv('500_P0_soil_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cLisSMGXQEMr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "cLisSMGXQEMr",
    "outputId": "6c6d0715-9015-4392-ef53-129c04a4de18"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_999d60f8-f0b2-4948-ab60-8e50d53393c3\", \"500_PA_metadata_train.csv\", 30256)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_0c54254c-f5d4-472d-8d95-48a2d5eba354\", \"500_P0_metadata_train.csv\", 46970)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_a0759153-a61e-4303-8239-df008730cb1e\", \"500_PA_soil_train.csv\", 27074)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_dc8471d2-516f-4854-80f4-23fa3fd8ed93\", \"500_P0_soil_train.csv\", 24480)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload the files directly using this method\n",
    "files.download('500_PA_metadata_train.csv')\n",
    "files.download('500_P0_metadata_train.csv')\n",
    "files.download('500_PA_soil_train.csv')\n",
    "files.download('500_P0_soil_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8qHSXlk7o98p",
   "metadata": {
    "id": "8qHSXlk7o98p"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets with the new names\n",
    "PA_metadata_train_top500_file = '500_PA_metadata_train.csv'\n",
    "P0_metadata_train_top500_file = '500_P0_metadata_train.csv'\n",
    "PA_soil_train_top500_file = '500_PA_soil_train.csv'\n",
    "PA_soil_train_top500_file = '500_P0_soil_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HXRmDdACpoBY",
   "metadata": {
    "id": "HXRmDdACpoBY"
   },
   "outputs": [],
   "source": [
    "PA_metadata_train_top500 = pd.read_csv(PA_metadata_train_top500_file)\n",
    "P0_metadata_train_top500 = pd.read_csv(P0_metadata_train_top500_file)\n",
    "PA_soil_train_top500 = pd.read_csv(PA_soil_train_top500_file)\n",
    "P0_soil_train_top500 = pd.read_csv(PA_soil_train_top500_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xqpdMzI2RZnq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xqpdMzI2RZnq",
    "outputId": "6baa12fe-0cea-4754-f2ac-9289dfd0261b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   lon                500 non-null    float64\n",
      " 1   lat                500 non-null    float64\n",
      " 2   year               500 non-null    int64  \n",
      " 3   geoUncertaintyInM  476 non-null    float64\n",
      " 4   areaInM2           452 non-null    float64\n",
      " 5   region             500 non-null    object \n",
      " 6   country            500 non-null    object \n",
      " 7   speciesId          500 non-null    float64\n",
      " 8   surveyId           500 non-null    int64  \n",
      "dtypes: float64(5), int64(2), object(2)\n",
      "memory usage: 35.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   publisher          500 non-null    object \n",
      " 1   year               500 non-null    int64  \n",
      " 2   month              500 non-null    float64\n",
      " 3   day                500 non-null    float64\n",
      " 4   lat                500 non-null    float64\n",
      " 5   lon                500 non-null    float64\n",
      " 6   geoUncertaintyInM  500 non-null    float64\n",
      " 7   taxonRank          500 non-null    object \n",
      " 8   date               500 non-null    object \n",
      " 9   dayOfYear          500 non-null    int64  \n",
      " 10  speciesId          500 non-null    float64\n",
      " 11  surveyId           500 non-null    int64  \n",
      "dtypes: float64(6), int64(3), object(3)\n",
      "memory usage: 47.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   surveyId           500 non-null    int64  \n",
      " 1   Soilgrid-bdod      409 non-null    float64\n",
      " 2   Soilgrid-cec       411 non-null    float64\n",
      " 3   Soilgrid-cfvo      411 non-null    float64\n",
      " 4   Soilgrid-clay      411 non-null    float64\n",
      " 5   Soilgrid-nitrogen  411 non-null    float64\n",
      " 6   Soilgrid-phh2o     411 non-null    float64\n",
      " 7   Soilgrid-sand      411 non-null    float64\n",
      " 8   Soilgrid-silt      411 non-null    float64\n",
      " 9   Soilgrid-soc       409 non-null    float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 39.2 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   surveyId           500 non-null    int64  \n",
      " 1   Soilgrid-bdod      409 non-null    float64\n",
      " 2   Soilgrid-cec       411 non-null    float64\n",
      " 3   Soilgrid-cfvo      411 non-null    float64\n",
      " 4   Soilgrid-clay      411 non-null    float64\n",
      " 5   Soilgrid-nitrogen  411 non-null    float64\n",
      " 6   Soilgrid-phh2o     411 non-null    float64\n",
      " 7   Soilgrid-sand      411 non-null    float64\n",
      " 8   Soilgrid-silt      411 non-null    float64\n",
      " 9   Soilgrid-soc       409 non-null    float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 39.2 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>surveyId</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soilgrid-bdod</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soilgrid-cec</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soilgrid-cfvo</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soilgrid-clay</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soilgrid-nitrogen</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soilgrid-phh2o</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soilgrid-sand</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soilgrid-silt</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soilgrid-soc</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "surveyId              0\n",
       "Soilgrid-bdod        91\n",
       "Soilgrid-cec         89\n",
       "Soilgrid-cfvo        89\n",
       "Soilgrid-clay        89\n",
       "Soilgrid-nitrogen    89\n",
       "Soilgrid-phh2o       89\n",
       "Soilgrid-sand        89\n",
       "Soilgrid-silt        89\n",
       "Soilgrid-soc         91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menelaah Data\n",
    "\n",
    "# Memeriksa struktur dataset\n",
    "PA_metadata_train_top500.info()\n",
    "P0_metadata_train_top500.info()\n",
    "PA_soil_train_top500.info()\n",
    "P0_soil_train_top500.info()\n",
    "\n",
    "# Memeriksa beberapa baris pertama\n",
    "PA_metadata_train_top500.head()\n",
    "P0_metadata_train_top500.head()\n",
    "PA_soil_train_top500.head()\n",
    "P0_soil_train_top500.head()\n",
    "\n",
    "# Memeriksa nilai yang hilang\n",
    "PA_metadata_train_top500.isnull().sum()\n",
    "P0_metadata_train_top500.isnull().sum()\n",
    "PA_soil_train_top500.isnull().sum()\n",
    "P0_soil_train_top500.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fDv5R27s_8Z",
   "metadata": {
    "id": "0fDv5R27s_8Z"
   },
   "source": [
    "Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bjUepvEdXA-j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjUepvEdXA-j",
    "outputId": "e7cbd838-72a2-41e0-e60c-bf1633443dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai yang hilang pada PA_metadata_train_top500:\n",
      "lon                   0\n",
      "lat                   0\n",
      "year                  0\n",
      "geoUncertaintyInM    24\n",
      "areaInM2             48\n",
      "region                0\n",
      "country               0\n",
      "speciesId             0\n",
      "surveyId              0\n",
      "dtype: int64\n",
      "Nilai yang hilang pada P0_metadata_train_top500:\n",
      "publisher            0\n",
      "year                 0\n",
      "month                0\n",
      "day                  0\n",
      "lat                  0\n",
      "lon                  0\n",
      "geoUncertaintyInM    0\n",
      "taxonRank            0\n",
      "date                 0\n",
      "dayOfYear            0\n",
      "speciesId            0\n",
      "surveyId             0\n",
      "dtype: int64\n",
      "Nilai yang hilang pada PA_soil_train_top500:\n",
      "surveyId              0\n",
      "Soilgrid-bdod        91\n",
      "Soilgrid-cec         89\n",
      "Soilgrid-cfvo        89\n",
      "Soilgrid-clay        89\n",
      "Soilgrid-nitrogen    89\n",
      "Soilgrid-phh2o       89\n",
      "Soilgrid-sand        89\n",
      "Soilgrid-silt        89\n",
      "Soilgrid-soc         91\n",
      "dtype: int64\n",
      "Nilai yang hilang pada P0_soil_train_top500:\n",
      "surveyId              0\n",
      "Soilgrid-bdod        91\n",
      "Soilgrid-cec         89\n",
      "Soilgrid-cfvo        89\n",
      "Soilgrid-clay        89\n",
      "Soilgrid-nitrogen    89\n",
      "Soilgrid-phh2o       89\n",
      "Soilgrid-sand        89\n",
      "Soilgrid-silt        89\n",
      "Soilgrid-soc         91\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Memeriksa nilai yang hilang pada setiap kolom\n",
    "PA_metadata_train_top500_missing = PA_metadata_train_top500.isnull().sum()\n",
    "P0_metadata_train_top500_missing = P0_metadata_train_top500.isnull().sum()\n",
    "PA_soil_train_top500_missing = PA_soil_train_top500.isnull().sum()\n",
    "P0_soil_train_top500_missing = P0_soil_train_top500.isnull().sum()\n",
    "\n",
    "# Menampilkan jumlah nilai yang hilang per kolom\n",
    "print(\"Nilai yang hilang pada PA_metadata_train_top500:\")\n",
    "print(PA_metadata_train_top500_missing)\n",
    "\n",
    "print(\"Nilai yang hilang pada P0_metadata_train_top500:\")\n",
    "print(P0_metadata_train_top500_missing)\n",
    "\n",
    "print(\"Nilai yang hilang pada PA_soil_train_top500:\")\n",
    "print(PA_soil_train_top500_missing)\n",
    "\n",
    "print(\"Nilai yang hilang pada P0_soil_train_top500:\")\n",
    "print(P0_soil_train_top500_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J0xDxpO8s9QY",
   "metadata": {
    "id": "J0xDxpO8s9QY"
   },
   "outputs": [],
   "source": [
    "# Menggunakan mean dan median untuk mengisi missing value pada PA metadata\n",
    "PA_metadata_train_top500.loc[:, 'geoUncertaintyInM'] = PA_metadata_train_top500['geoUncertaintyInM'].fillna(PA_metadata_train_top500['geoUncertaintyInM'].mean())\n",
    "PA_metadata_train_top500.loc[:, 'areaInM2'] = PA_metadata_train_top500['areaInM2'].fillna(PA_metadata_train_top500['areaInM2'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CKAU1JgdXKig",
   "metadata": {
    "id": "CKAU1JgdXKig"
   },
   "outputs": [],
   "source": [
    "# Mengatasi Nilai yang Hilang pada PA_soil_train_top500\n",
    "PA_soil_train_top500 = PA_soil_train_top500.copy()\n",
    "\n",
    "# Lanjutkan imputasi\n",
    "PA_soil_train_top500['Soilgrid-bdod'] = PA_soil_train_top500['Soilgrid-bdod'].fillna(PA_soil_train_top500['Soilgrid-bdod'].mean())\n",
    "PA_soil_train_top500['Soilgrid-cec'] = PA_soil_train_top500['Soilgrid-cec'].fillna(PA_soil_train_top500['Soilgrid-cec'].mean())\n",
    "PA_soil_train_top500['Soilgrid-cfvo'] = PA_soil_train_top500['Soilgrid-cfvo'].fillna(PA_soil_train_top500['Soilgrid-cfvo'].mean())\n",
    "PA_soil_train_top500['Soilgrid-clay'] = PA_soil_train_top500['Soilgrid-clay'].fillna(PA_soil_train_top500['Soilgrid-clay'].mean())\n",
    "PA_soil_train_top500['Soilgrid-nitrogen'] = PA_soil_train_top500['Soilgrid-nitrogen'].fillna(PA_soil_train_top500['Soilgrid-nitrogen'].mean())\n",
    "PA_soil_train_top500['Soilgrid-phh2o'] = PA_soil_train_top500['Soilgrid-phh2o'].fillna(PA_soil_train_top500['Soilgrid-phh2o'].mean())\n",
    "PA_soil_train_top500['Soilgrid-sand'] = PA_soil_train_top500['Soilgrid-sand'].fillna(PA_soil_train_top500['Soilgrid-sand'].mean())\n",
    "PA_soil_train_top500['Soilgrid-silt'] = PA_soil_train_top500['Soilgrid-silt'].fillna(PA_soil_train_top500['Soilgrid-silt'].mean())\n",
    "PA_soil_train_top500['Soilgrid-soc'] = PA_soil_train_top500['Soilgrid-soc'].fillna(PA_soil_train_top500['Soilgrid-soc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rp_tlPnavtpw",
   "metadata": {
    "id": "rp_tlPnavtpw"
   },
   "outputs": [],
   "source": [
    "# Mengatasi Nilai yang Hilang pada P0_soil_train_top500\n",
    "P0_soil_train_top500_copy = P0_soil_train_top500.copy()\n",
    "\n",
    "# Imputasi nilai yang hilang pada P0_soil_train_top500_copy dengan rata-rata\n",
    "P0_soil_train_top500_copy['Soilgrid-bdod'] = P0_soil_train_top500_copy['Soilgrid-bdod'].fillna(P0_soil_train_top500_copy['Soilgrid-bdod'].mean())\n",
    "P0_soil_train_top500_copy['Soilgrid-cec'] = P0_soil_train_top500_copy['Soilgrid-cec'].fillna(P0_soil_train_top500_copy['Soilgrid-cec'].mean())\n",
    "P0_soil_train_top500_copy['Soilgrid-cfvo'] = P0_soil_train_top500_copy['Soilgrid-cfvo'].fillna(P0_soil_train_top500_copy['Soilgrid-cfvo'].mean())\n",
    "P0_soil_train_top500_copy['Soilgrid-clay'] = P0_soil_train_top500_copy['Soilgrid-clay'].fillna(P0_soil_train_top500_copy['Soilgrid-clay'].mean())\n",
    "P0_soil_train_top500_copy['Soilgrid-nitrogen'] = P0_soil_train_top500_copy['Soilgrid-nitrogen'].fillna(P0_soil_train_top500_copy['Soilgrid-nitrogen'].mean())\n",
    "P0_soil_train_top500_copy['Soilgrid-phh2o'] = P0_soil_train_top500_copy['Soilgrid-phh2o'].fillna(P0_soil_train_top500_copy['Soilgrid-phh2o'].mean())\n",
    "P0_soil_train_top500_copy['Soilgrid-sand'] = P0_soil_train_top500_copy['Soilgrid-sand'].fillna(P0_soil_train_top500_copy['Soilgrid-sand'].mean())\n",
    "P0_soil_train_top500_copy['Soilgrid-silt'] = P0_soil_train_top500_copy['Soilgrid-silt'].fillna(P0_soil_train_top500_copy['Soilgrid-silt'].mean())\n",
    "P0_soil_train_top500_copy['Soilgrid-soc'] = P0_soil_train_top500_copy['Soilgrid-soc'].fillna(P0_soil_train_top500_copy['Soilgrid-soc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X5cpo2rNdTBc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5cpo2rNdTBc",
    "outputId": "3ffd29ad-0412-42d9-a830-289e4fe20b03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [lat, lon, geoUncertaintyInM, speciesId, surveyId, Soilgrid-bdod, Soilgrid-cec, Soilgrid-cfvo, Soilgrid-clay, Soilgrid-nitrogen, Soilgrid-phh2o, Soilgrid-sand, Soilgrid-silt, Soilgrid-soc]\n",
      "Index: []\n",
      "Data yang telah digabungkan telah disimpan.\n"
     ]
    }
   ],
   "source": [
    "# Menggabungkan PA metadata dan PA soil berdasarkan surveyId\n",
    "PA_metadata_selected = PA_metadata_train_top500[['lat', 'lon', 'geoUncertaintyInM', 'speciesId', 'surveyId']]\n",
    "PA_soil_selected = PA_soil_train_top500[['surveyId', 'Soilgrid-bdod', 'Soilgrid-cec', 'Soilgrid-cfvo',\n",
    "                                         'Soilgrid-clay', 'Soilgrid-nitrogen', 'Soilgrid-phh2o',\n",
    "                                         'Soilgrid-sand', 'Soilgrid-silt', 'Soilgrid-soc']]\n",
    "\n",
    "# Gabungkan PA metadata dengan PA soil berdasarkan surveyId\n",
    "PA_merged = pd.merge(PA_metadata_selected, PA_soil_selected, on='surveyId', how='inner')\n",
    "\n",
    "# Menampilkan hasil gabungan PA metadata dan PA soil\n",
    "print(PA_merged.head())\n",
    "\n",
    "# Langkah 3: Menyimpan hasil gabungan ke file CSV\n",
    "PA_merged.to_csv('PA_merged.csv', index=False)\n",
    "print(\"Data yang telah digabungkan telah disimpan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZettducmdxHm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZettducmdxHm",
    "outputId": "195b4f01-a8f5-4293-f778-691a85c6e4da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lat       lon  geoUncertaintyInM  speciesId  surveyId  Soilgrid-bdod  \\\n",
      "0  43.74605  1.573057                6.0     3383.0         1          145.0   \n",
      "1  42.12559  0.314948                5.0     1152.0         2          134.0   \n",
      "2  48.29520 -0.934518               24.9     6772.0         3          127.0   \n",
      "3  53.63367 -2.644535                8.0     3318.0         4          103.0   \n",
      "4  49.79471  7.925086               15.0     3374.0         5          138.0   \n",
      "\n",
      "   Soilgrid-cec  Soilgrid-cfvo  Soilgrid-clay  Soilgrid-nitrogen  \\\n",
      "0         212.0          130.0          303.0              134.0   \n",
      "1         213.0          189.0          302.0              184.0   \n",
      "2         211.0          109.0          187.0              257.0   \n",
      "3         212.0          123.0          216.0              466.0   \n",
      "4         195.0          131.0          310.0              198.0   \n",
      "\n",
      "   Soilgrid-phh2o  Soilgrid-sand  Soilgrid-silt  Soilgrid-soc  \n",
      "0            73.0          306.0          389.0         122.0  \n",
      "1            74.0          294.0          403.0         223.0  \n",
      "2            59.0          132.0          681.0         301.0  \n",
      "3            56.0          429.0          355.0        1044.0  \n",
      "4            73.0          208.0          480.0         208.0  \n",
      "Data yang telah digabungkan telah disimpan.\n"
     ]
    }
   ],
   "source": [
    "# Menggabungkan PO metadata dan PO soil berdasarkan surveyId\n",
    "P0_metadata_selected = P0_metadata_train_top500[['lat', 'lon', 'geoUncertaintyInM', 'speciesId', 'surveyId']]\n",
    "P0_soil_selected = P0_soil_train_top500[['surveyId', 'Soilgrid-bdod', 'Soilgrid-cec', 'Soilgrid-cfvo',\n",
    "                                         'Soilgrid-clay', 'Soilgrid-nitrogen', 'Soilgrid-phh2o',\n",
    "                                         'Soilgrid-sand', 'Soilgrid-silt', 'Soilgrid-soc']]\n",
    "\n",
    "# Gabungkan PO metadata dengan PO soil berdasarkan surveyId\n",
    "PO_merged = pd.merge(P0_metadata_selected, P0_soil_selected, on='surveyId', how='inner')\n",
    "\n",
    "# Menampilkan hasil gabungan PO metadata dan PO soil\n",
    "print(PO_merged.head())\n",
    "\n",
    "# Langkah 3: Menyimpan hasil gabungan ke file CSV\n",
    "PO_merged.to_csv('PO_merged.csv', index=False)\n",
    "print(\"Data yang telah digabungkan telah disimpan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefCPTmcgy59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fefCPTmcgy59",
    "outputId": "fdf1ffc5-1e28-4b4f-94fa-b6f381728490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom yang sama antara PA_merged dan PO_merged:\n",
      "Index(['lat', 'lon', 'geoUncertaintyInM', 'speciesId', 'surveyId',\n",
      "       'Soilgrid-bdod', 'Soilgrid-cec', 'Soilgrid-cfvo', 'Soilgrid-clay',\n",
      "       'Soilgrid-nitrogen', 'Soilgrid-phh2o', 'Soilgrid-sand', 'Soilgrid-silt',\n",
      "       'Soilgrid-soc'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Mencari fitur yang akan digunakan untuk train\n",
    "\n",
    "# Menampilkan kolom-kolom yang ada pada PA_merged dan PO_merged\n",
    "PA_columns = PA_merged.columns\n",
    "PO_columns = PO_merged.columns\n",
    "\n",
    "# Mencari kolom yang sama antara PA_merged dan PO_merged\n",
    "common_columns = PA_columns.intersection(PO_columns)\n",
    "\n",
    "# Menampilkan kolom yang sama\n",
    "print(\"Kolom yang sama antara PA_merged dan PO_merged:\")\n",
    "print(common_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ucUXLTuHqaDj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ucUXLTuHqaDj",
    "outputId": "eb0924d1-ac0e-4c23-ca44-3a0f5f8b7e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lat       lon  geoUncertaintyInM  speciesId  surveyId  Soilgrid-bdod  \\\n",
      "0  43.74605  1.573057                6.0     3383.0         1          145.0   \n",
      "1  42.12559  0.314948                5.0     1152.0         2          134.0   \n",
      "2  48.29520 -0.934518               24.9     6772.0         3          127.0   \n",
      "3  53.63367 -2.644535                8.0     3318.0         4          103.0   \n",
      "4  49.79471  7.925086               15.0     3374.0         5          138.0   \n",
      "\n",
      "   Soilgrid-cec  Soilgrid-cfvo  Soilgrid-clay  Soilgrid-nitrogen  \\\n",
      "0         212.0          130.0          303.0              134.0   \n",
      "1         213.0          189.0          302.0              184.0   \n",
      "2         211.0          109.0          187.0              257.0   \n",
      "3         212.0          123.0          216.0              466.0   \n",
      "4         195.0          131.0          310.0              198.0   \n",
      "\n",
      "   Soilgrid-phh2o  Soilgrid-sand  Soilgrid-silt  Soilgrid-soc  \n",
      "0            73.0          306.0          389.0         122.0  \n",
      "1            74.0          294.0          403.0         223.0  \n",
      "2            59.0          132.0          681.0         301.0  \n",
      "3            56.0          429.0          355.0        1044.0  \n",
      "4            73.0          208.0          480.0         208.0  \n",
      "Data yang telah digabungkan dan disimpan sebagai final_merged_data.csv.\n"
     ]
    }
   ],
   "source": [
    "# Pilih hanya kolom yang relevan (kolom yang sama antara PA_merged dan PO_merged)\n",
    "common_columns = ['lat', 'lon', 'geoUncertaintyInM', 'speciesId', 'surveyId',\n",
    "                  'Soilgrid-bdod', 'Soilgrid-cec', 'Soilgrid-cfvo', 'Soilgrid-clay',\n",
    "                  'Soilgrid-nitrogen', 'Soilgrid-phh2o', 'Soilgrid-sand', 'Soilgrid-silt',\n",
    "                  'Soilgrid-soc']\n",
    "\n",
    "PA_merged_selected = PA_merged[common_columns]\n",
    "PO_merged_selected = PO_merged[common_columns]\n",
    "\n",
    "# Menggabungkan PA_merged_selected dan PO_merged_selected secara vertikal\n",
    "final_merged_data = pd.concat([PA_merged_selected, PO_merged_selected], axis=0, ignore_index=True)\n",
    "\n",
    "# Menampilkan beberapa baris pertama dari final_merged_data untuk memastikan hasil gabungan\n",
    "print(final_merged_data.head())\n",
    "\n",
    "# Menyimpan final_merged_data ke dalam file CSV\n",
    "final_merged_data.to_csv('final_merged_data.csv', index=False)\n",
    "print(\"Data yang telah digabungkan dan disimpan sebagai final_merged_data.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5mFpZLTmwWCH",
   "metadata": {
    "id": "5mFpZLTmwWCH"
   },
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zgnmAmPg8C7y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zgnmAmPg8C7y",
    "outputId": "81fb3aac-aea3-4110-c106-a21e164514f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat                   0\n",
      "lon                   0\n",
      "geoUncertaintyInM     0\n",
      "speciesId             0\n",
      "surveyId              0\n",
      "Soilgrid-bdod        89\n",
      "Soilgrid-cec         81\n",
      "Soilgrid-cfvo        81\n",
      "Soilgrid-clay        81\n",
      "Soilgrid-nitrogen    81\n",
      "Soilgrid-phh2o       81\n",
      "Soilgrid-sand        81\n",
      "Soilgrid-silt        81\n",
      "Soilgrid-soc         89\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Memeriksa apakah ada nilai kosong (NaN) di seluruh dataframe\n",
    "print(final_merged_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HZjhgB-5wVk0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZjhgB-5wVk0",
    "outputId": "8779fccf-15c5-47cb-d43b-aac1c221b789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.060\n",
      "Prediction file saved as submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier # Example model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the datasets (already done, using final_merged_data here for training)\n",
    "train_data = pd.read_csv('final_merged_data.csv')\n",
    "\n",
    "# Prepare feature columns (excluding the target column 'speciesId')\n",
    "X = train_data.drop(columns=['speciesId', 'surveyId'])\n",
    "\n",
    "# The target is the 'speciesId' column\n",
    "y = train_data['speciesId']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model (RandomForest for this example)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy (optional, to evaluate the model)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Now we need to format the predictions as per the requirement\n",
    "# Assume 'surveyId' for the test samples is available (this is a sample test dataset)\n",
    "test_data = X_test.copy() # Using X_test for predictions here\n",
    "\n",
    "# Get predictions for the test samples\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Create the 'predictions' column with space-separated species IDs for each test sample\n",
    "# We will need to group by 'surveyId' and sort predictions by speciesId\n",
    "output = pd.DataFrame({'surveyId': test_data.index, 'X_test': test_data.index, 'predictions': predictions})\n",
    "\n",
    "# Ensure predictions are sorted in increasing order\n",
    "output['predictions'] = output.groupby('surveyId')['predictions'].transform(lambda x: ' '.join(map(str, sorted(x))))\n",
    "\n",
    "# Drop duplicates for surveyId, keeping only one row per surveyId\n",
    "output = output.drop_duplicates(subset=['surveyId'])\n",
    "\n",
    "# Save the result as CSV\n",
    "output[['surveyId', 'predictions']].to_csv('submission.csv', index=False)\n",
    "print(\"Prediction file saved as submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bX5qkyIp42JA",
   "metadata": {
    "id": "bX5qkyIp42JA"
   },
   "source": [
    "Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2-Awlzp446H1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-Awlzp446H1",
    "outputId": "0e981ad3-9646-4880-babd-aca3649f6ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (weighted average): 0.057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Evaluasi dengan F1 Score (weighted average untuk seluruh kelas)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1 Score (weighted average): {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bPI7bXi9y0M5",
   "metadata": {
    "id": "bPI7bXi9y0M5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
